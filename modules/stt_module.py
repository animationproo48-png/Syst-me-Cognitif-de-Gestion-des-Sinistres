"""
Module Speech-to-Text (STT) Intelligent pour ClaimAI.
FonctionnalitÃ©s :
1. Transcription Audio (PrioritÃ© API LemonFox, Fallback Local Faster-Whisper)
2. Auto-dÃ©tection langue
3. Traduction Automatique (Darija -> FranÃ§ais Pro via Groq)
"""

import os
import re
import requests
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv

# Import pour les type hints uniquement
from models.claim_models import TranscriptMetadata


# --- Moteur Principal ---
class STTEngine:
    def __init__(self, model_name: str = "large-v3", use_api: bool = True):
        """
        Initialise le moteur STT.
        Args:
            model_name: ModÃ¨le Whisper (large-v3 est vital pour le Darija).
            use_api: Si True, tente d'utiliser LemonFox avant le modÃ¨le local.
        """
        load_dotenv()
        self.api_key = os.getenv("WHISPER_API_KEY")
        self.groq_key = os.getenv("GROQ_API_KEY")  # Seulement Groq pour la traduction
        self.model_name = model_name
        self.use_api = use_api
        self.local_model = None
        
        # --- LE SECRET DU DARIJA ---
        # Ce prompt force l'IA Ã  rester dans le contexte dialectal marocain + assurance
        self.darija_prompt = (
            "Ù‡Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠÙ‡ Ø§Ù„Ø¯Ø§Ø±Ø¬Ø© Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ© Ø¯ÙŠØ§Ù„ ÙˆØ§Ø­Ø¯ Ø§Ù„Ø³ÙŠØ¯ Ø¯Ø§Ø± ÙƒØ³ÙŠØ¯Ø©. "
            "Ø§Ù„Ø³ÙŠØ§Ø±Ø©ØŒ Ø§Ù„ÙƒØ³ÙŠØ¯Ø©ØŒ Ø§Ù„Ù…ÙˆØªÙˆØ±ØŒ Ù„ÙˆØªÙˆØ±ÙˆØªØŒ ÙƒØ§ÙŠÙ†ØŒ Ø¨Ø²Ø§ÙØŒ Ø¯Ø§Ø¨Ø§ØŒ ÙˆØ§Ø®Ø§ØŒ ØµØ§ÙÙŠØŒ "
            "Ø§Ù„ÙƒÙˆÙ†ØµØ·Ø§ØŒ Ù„Ø§Ø³ÙŠØ±ÙˆÙ†Ø³ØŒ Ø§Ù„Ø·ÙˆÙ…ÙˆØ¨ÙŠÙ„ØŒ Ø§Ù„Ø¨Ø§Ø±Ø´ÙˆØŒ Ø§Ù„Ø¨Ø§Ø±Ø¨Ø±ÙŠØ²."
        )

        # Chargement prÃ©ventif du modÃ¨le local si pas d'API
        if not use_api or not self.api_key:
            self._load_local_model()

    def _load_local_model(self):
        """Charge Faster-Whisper (optimisÃ© CPU/GPU)."""
        try:
            from faster_whisper import WhisperModel
            print(f"ğŸ“¥ Chargement du modÃ¨le local '{self.model_name}' (Fallback)...")
            # compute_type="int8" permet de faire tourner le gros modÃ¨le sur un CPU standard
            self.local_model = WhisperModel(self.model_name, device="cpu", compute_type="int8")
            print("âœ… ModÃ¨le local prÃªt.")
        except ImportError:
            print("âš ï¸ Module 'faster-whisper' non trouvÃ©. Le mode local ne fonctionnera pas.")

    def transcribe_audio(self, audio_path: str, language: str = None) -> Optional[TranscriptMetadata]:
        """
        Fonction principale : Transcrit ET Traduit.
        STRATÃ‰GIE: Auto-dÃ©tection de langue, transcription fidÃ¨le, puis traduction si arabe.
        
        Args:
            audio_path: Chemin du fichier audio
            language: Langue forcÃ©e (fr, ar, en) - Si None, auto-dÃ©tection
        """
        if not os.path.exists(audio_path):
            print(f"âŒ Fichier introuvable : {audio_path}")
            return None

        metadata = None

        # Ã‰TAPE 1 : TRANSCRIPTION AVEC LANGUE FORCÃ‰E OU AUTO-DÃ‰TECTION
        # --------------------------------------------
        if self.use_api and self.api_key:
            try:
                metadata = self._transcribe_with_api(audio_path, use_prompt=False, force_language=language)
            except Exception as e:
                print(f"âš ï¸ Erreur API LemonFox ({e}). Passage en local...")
        
        # Fallback Local si l'API a Ã©chouÃ© ou n'est pas active
        if metadata is None and self.local_model:
            metadata = self._transcribe_with_local_model(audio_path, language)

        # Si tout a Ã©chouÃ©
        if metadata is None:
            return self._simulate_error()

        # Ã‰TAPE 2 : TRADUCTION SI LANGUE ARABE DÃ‰TECTÃ‰E
        # -----------------------------------------------
        # VÃ©rifier toutes les variantes d'arabe (ar, ara, arabic, ar-MA, ar-EG, etc.)
        detected_lang = metadata.language.lower() if metadata.language else ""
        is_arabic = any(marker in detected_lang for marker in ["ar", "arabic", "Ø¹Ø±Ø¨ÙŠ"])
        
        # Si langue inconnue, vÃ©rifier si le texte contient des caractÃ¨res arabes
        if not is_arabic and detected_lang in ["unknown", "", "none"]:
            has_arabic_chars = bool(re.search(r'[\u0600-\u06FF]', metadata.original_transcript))
            if has_arabic_chars:
                is_arabic = True
                print("ğŸ” DÃ©tection: CaractÃ¨res arabes trouvÃ©s dans le texte")
        
        if is_arabic:
            if self.groq_key:
                print(f"ğŸ¤– Langue arabe dÃ©tectÃ©e - Lancement traduction Groq...")
                translation = self._translate_with_llm(metadata.original_transcript)
                
                if translation:
                    metadata.normalized_transcript = translation
                    print(f"âœ… Traduction: {translation[:80]}...")
                else:
                    print("âš ï¸ Traduction Ã©chouÃ©e, conservation du texte original.")
            else:
                print("âš ï¸ Pas de clÃ© Groq - traduction dÃ©sactivÃ©e")
        else:
            print(f"â„¹ï¸ Langue dÃ©tectÃ©e: {metadata.language} - Pas de traduction nÃ©cessaire")

        return metadata

    def _transcribe_with_api(self, audio_path: str, use_prompt: bool = False, force_language: str = None) -> TranscriptMetadata:
        """Appel API LemonFox avec option de forcer la langue."""
        url = "https://api.lemonfox.ai/v1/audio/transcriptions"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        
        with open(audio_path, 'rb') as f:
            files = {"file": f}
            data = {
                "response_format": "json"
            }
            
            # Si une langue est forcÃ©e, l'ajouter
            if force_language:
                data["language"] = force_language
                print(f"ğŸŒ Envoi Ã  LemonFox (langue forcÃ©e: {force_language})...")
            else:
                print(f"ğŸŒ Envoi Ã  LemonFox (auto-dÃ©tection langue pure)...")
            
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()

        result = response.json()
        text = result.get("text", "").strip()
        detected_lang = force_language if force_language else result.get("language", "unknown")
        
        print(f"ğŸ“ Langue: {detected_lang}")
        print(f"ğŸ“ Transcription: {text[:80]}...")
        
        # Retourner un objet Pydantic TranscriptMetadata
        return TranscriptMetadata(
            original_transcript=text,
            normalized_transcript=self._basic_cleanup(text),
            language=detected_lang,
            confidence_score=result.get("confidence", 0.9),
            emotional_markers=self._detect_emotions(text),
            hesitations=self._count_hesitations(text),
            duration_seconds=result.get("duration", 0.0)
        )

    def _transcribe_with_local_model(self, audio_path: str, language: str) -> TranscriptMetadata:
        """Utilisation de Faster-Whisper en local."""
        print("ğŸ–¥ï¸ Transcription locale en cours...")
        segments, info = self.local_model.transcribe(
            audio_path, 
            language=language, 
            initial_prompt=self.darija_prompt,
            vad_filter=True # Supprime les silences avant transcription
        )
        
        full_text = " ".join([seg.text for seg in segments]).strip()
        
        # Retourner un objet Pydantic TranscriptMetadata
        return TranscriptMetadata(
            original_transcript=full_text,
            normalized_transcript=self._basic_cleanup(full_text),
            language=info.language,
            confidence_score=info.language_probability,
            emotional_markers=self._detect_emotions(full_text),
            hesitations=self._count_hesitations(full_text),
            duration_seconds=info.duration
        )

    def _translate_with_llm(self, text: str) -> Optional[str]:
        """Traduction via Groq avec prompt enrichi et dictionnaire darija."""
        
        if not self.groq_key:
            print("âš ï¸ ClÃ© Groq manquante, traduction impossible")
            return None
        
        try:
            from groq import Groq
            client = Groq(api_key=self.groq_key)
            
            # Instructions systÃ¨me pour le modÃ¨le
            system_prompt = (
                "Tu es un expert en traduction du Darija marocain vers le franÃ§ais professionnel pour les assurances. "
                "Traduis fidÃ¨lement le texte suivant en utilisant le dictionnaire de rÃ©fÃ©rence. "
                "Si le texte est dÃ©jÃ  en franÃ§ais, corrige simplement la syntaxe."
            )
            
            # Dictionnaire darija marocain -> franÃ§ais (contexte assurance)
            context_dictionary = """
DICTIONNAIRE DARIJA MAROCAIN â†’ FRANÃ‡AIS (Assurance Automobile):

VÃ©hicule & Accident:
- Ø§Ù„Ø·ÙˆÙ…ÙˆØ¨ÙŠÙ„ / Ø§Ù„Ø·ÙˆÙ†ÙˆØ¨ÙŠÙ„ / Ù„ÙˆØ·Ùˆ = la voiture, le vÃ©hicule
- Ø§Ù„ÙƒØ³ÙŠØ¯Ø©/ÙƒØ³ÙŠØ¯Ø© / Ù„ÙƒØ³ÙŠØ¯Ø© = l'accident
- Ø¯Ø±Øª ÙƒØ³ÙŠØ¯Ø© = j'ai eu un accident
- ØªØµØ§Ø¯Ù… = collision, accrochage
- Ù„ÙˆØªÙˆØ±ÙˆØª = l'autoroute
- Ø§Ù„Ø·Ø±ÙŠÙ‚ = la route
- Ù„Ø¨Ø§Ø±Ø¨Ø±ÙŠØ² = le pare-brise
- Ø§Ù„Ù…ÙˆØªÙˆØ± = la moto
- Ø§Ù„ÙØ±Ø§Ù…Ù„ = les freins
- Ø§Ù„Ø±ÙˆÙŠØ¶Ø© = les roues
- Ù„ÙƒØ§Ø¨Ùˆ = le capot
- Ù„Ø¨Ø§Ø±Ø´Ùˆ = le pare-chocs
- ØµØ¯Ù…Ø© / ØµØ¯Ø§Ù… = choc, impact

Parties & ResponsabilitÃ©:
- Ø¯Ø§Ø± Ù…Ø¹Ø§ÙŠØ§ = il m'a percutÃ©
- ØµØ¯Ù…Ù†ÙŠ = il m'a heurtÃ©
- Ø£Ù†Ø§ Ø§Ù„Ù„ÙŠ ØµØ¯Ù…ØªÙˆ = c'est moi qui l'ai heurtÃ©
- Ù…Ø§Ø´ÙŠ ØºÙ„Ø·ÙŠ = ce n'est pas ma faute
- Ù‡Ùˆ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ = c'est lui le responsable
- Ø§Ù„Ø®Ø³Ø§Ø±Ø© = les dÃ©gÃ¢ts

Localisation:
- ÙÙƒØ§Ø²Ø§ / ÙØ§Ù„Ø¯Ø§Ø± Ø§Ù„Ø¨ÙŠØ¶Ø§ = Ã  Casablanca
- ÙØ§Ù„Ø±Ø¨Ø§Ø· = Ã  Rabat
- ÙÙ…Ø±Ø§ÙƒØ´ = Ã  Marrakech
- Ù‚Ø¯Ø§Ù… = devant
- Ù…Ù† ÙˆØ±Ø§ = par derriÃ¨re
- Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ† / Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø± = Ã  droite / Ã  gauche

Documents & Assurance:
- Ù„ÙƒÙˆÙ†ØµØ·Ø§ = le constat amiable
- Ù„Ø§Ø³ÙŠØ±ÙˆÙ†Ø³ = l'assurance
- Ù„Ø¨Ø§Ø¨ÙŠØ§Øª / Ù„ÙˆØ±Ø§Ù‚ = les papiers, documents
- Ø±Ù‚Ù… Ø§Ù„Ø´Ø§ØµÙŠ = numÃ©ro de chÃ¢ssis
- Ø¥Ù…Ø§ØªØ±ÙŠÙƒÙŠÙ„ / Ø§Ù„Ø±Ù‚Ù… = immatriculation, numÃ©ro de plaque

Expressions temporelles:
- Ø§Ù„Ø¨Ø§Ø±Ø­ = hier
- Ø§Ù„ÙŠÙˆÙ… = aujourd'hui
- Ø¯Ø§Ø¨Ø§ = maintenant, tout Ã  l'heure
- Ø§Ù„ØµØ¨Ø§Ø­ = le matin
- Ø§Ù„Ø¹Ø´ÙŠØ© = le soir
- Ù†Ù‡Ø§Ø± = jour

ModalitÃ©s:
- Ø¨Ø²Ø§Ù = beaucoup
- Ø´ÙˆÙŠØ© = un peu
- ÙˆØ§Ø®Ø§ = d'accord, mÃªme si
- ØµØ§ÙÙŠ = c'est tout, terminÃ©
- ÙŠØ¹Ù†ÙŠ / Ø²Ø¹Ù…Ø§ = c'est-Ã -dire
- ÙƒØ§ÙŠÙ† = il y a
- Ù…Ø§ÙƒØ§ÙŠÙ†Ø´ = il n'y a pas

EXEMPLES DE TRADUCTIONS:
Darija: "Ø¯Ø§Ø± Ù…Ø¹Ø§ÙŠØ§ ÙƒØ³ÙŠØ¯Ø© Ø§Ù„Ø¨Ø§Ø±Ø­ ÙÙ„ÙˆØªÙˆØ±ÙˆØª Ù‚Ø¯Ø§Ù… ÙƒØ§Ø²Ø§ØŒ Ø§Ù„Ø·ÙˆÙ…ÙˆØ¨ÙŠÙ„ Ø¯ÙŠØ§Ù„ÙŠ ØªØ®Ø³Ø±Ø§Øª Ø¨Ø²Ø§Ù"
FranÃ§ais: "J'ai eu un accident hier sur l'autoroute avant Casablanca, ma voiture a subi beaucoup de dÃ©gÃ¢ts"

Darija: "ÙˆØ§Ø­Ø¯ Ø§Ù„ÙƒØ§Ø±Ùˆ ØµØ¯Ù…Ù†ÙŠ Ù…Ù† ÙˆØ±Ø§ Ùˆ Ù„Ø¨Ø§Ø±Ø¨Ø±ÙŠØ² ØªÙƒØ³Ø±"
FranÃ§ais: "Une voiture m'a percutÃ© par derriÃ¨re et le pare-brise s'est brisÃ©"

Darija: "Ø®ØµÙ†ÙŠ Ù†ÙƒÙ…Ù„ Ù„ÙƒÙˆÙ†ØµØ·Ø§ Ùˆ Ù†Ø¯ÙŠØ± Ù„Ø¨Ø§Ø¨ÙŠØ§Øª Ø¯ÙŠØ§Ù„ Ù„Ø§Ø³ÙŠØ±ÙˆÙ†Ø³"
FranÃ§ais: "Je dois complÃ©ter le constat amiable et fournir les documents d'assurance"
"""
            
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": system_prompt + "\n" + context_dictionary},
                    {"role": "user", "content": f"Texte Ã  traduire : {text}"}
                ],
                temperature=0.1,
                max_tokens=800
            )
            
            translation = response.choices[0].message.content.strip()
            print(f"âœ¨ Traduction Groq enrichie: {translation[:70]}...")
            return translation
            
        except Exception as e:
            print(f"âŒ Erreur Groq: {str(e)[:60]}...")
            return None

    # --- Outils d'analyse ---
    
    def _basic_cleanup(self, text: str) -> str:
        """Nettoyage basique (espaces, retours ligne)."""
        return re.sub(r'\s+', ' ', text).strip()

    def _detect_emotions(self, text: str) -> List[str]:
        """DÃ©tecte les mots clÃ©s Ã©motionnels (Maroc & FranÃ§ais)."""
        emotions = []
        keywords = {
            "urgence": ["Ø¯ØºÙŠØ§", "vite", "urgent", "Ø¨Ø³Ø±Ø¹Ø©", "Ø¹ØªÙ‚Ù†ÙŠ"],
            "colÃ¨re": ["Ø­Ø´ÙˆÙ…Ø©", "Ã©nervÃ©", "scandale", "Ø§Ù„Ù„Ù‡ ÙŠØ§Ø®Ø° Ø§Ù„Ø­Ù‚"],
            "peur": ["Ø®Ø§ÙŠÙ", "peur", "tramp", "Ù…Ø®Ù„ÙˆØ¹"],
            "doute": ["ÙŠÙ…ÙƒÙ†", "je crois", "peut-Ãªtre", "waqila"]
        }
        text_lower = text.lower()
        for emotion, words in keywords.items():
            if any(w in text_lower for w in words):
                emotions.append(emotion)
        return list(set(emotions))

    def _count_hesitations(self, text: str) -> int:
        """Compte les hÃ©sitations vocales."""
        patterns = [r'\beuh\b', r'\buh\b', r'\bmmm\b', r'\bÙŠØ¹Ù†ÙŠ\b', r'\bØ²Ø¹Ù…Ø§\b']
        count = 0
        for p in patterns:
            count += len(re.findall(p, text, re.IGNORECASE))
        return count

    def _simulate_error(self):
        """Retourne un objet TranscriptMetadata d'erreur."""
        return TranscriptMetadata(
            original_transcript="Error",
            normalized_transcript="Error",
            language="en",
            confidence_score=0.0,
            emotional_markers=[],
            hesitations=0,
            duration_seconds=0.0
        )

# --- Bloc de Test ---
if __name__ == "__main__":
    # 1. Instanciation
    print("ğŸš€ Initialisation du moteur STT...")
    engine = STTEngine(model_name="large-v3", use_api=True)
    
    # 2. Chemin vers votre fichier audio de test (modifier le chemin)
    audio_file = "test_darija.mp3" 
    
    # CrÃ©ation d'un fichier dummy si inexistant pour Ã©viter le crash du test
    if not os.path.exists(audio_file):
        print(f"âš ï¸ Fichier {audio_file} absent. Veuillez mettre un vrai fichier audio.")
    else:
        # 3. ExÃ©cution
        result = engine.transcribe_audio(audio_file)
        
        # 4. Affichage RÃ©sultat
        if result:
            print("\n" + "="*50)
            print(f"ğŸ§ ORIGINAL (Darija) : {result.original_transcript}")
            print("-" * 50)
            print(f"ğŸ‡«ğŸ‡· TRADUIT (FranÃ§ais): {result.normalized_transcript}")
            print(f"ğŸ“Š Confiance : {result.confidence_score:.2f}")
            print(f"â¤ï¸ Ã‰motions : {result.emotional_markers}")
            print("="*50)