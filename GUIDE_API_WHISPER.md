# ğŸ™ï¸ Guide d'Utilisation API Whisper

## âœ… Statut de l'IntÃ©gration

**L'API Whisper est maintenant intÃ©grÃ©e et fonctionnelle !**

- **ClÃ© API** : ConfigurÃ©e dans `.env`
- **DÃ©pendances** : Toutes installÃ©es
- **Tests** : 4/4 rÃ©ussis âœ…

---

## ğŸš€ Modes de Fonctionnement

Le systÃ¨me STT fonctionne en 3 modes avec fallback automatique :

### 1. **Mode API** (PrioritÃ© 1) ğŸŒ
- Utilise l'API Whisper d'OpenAI
- Meilleure qualitÃ© de transcription
- Supporte tous les formats audio
- DÃ©tection automatique de la langue
- **Actif par dÃ©faut quand la clÃ© API est configurÃ©e**

### 2. **Mode Local** (PrioritÃ© 2) ğŸ–¥ï¸
- Utilise un modÃ¨le Whisper tÃ©lÃ©chargÃ© localement
- NÃ©cessite `pip install openai-whisper`
- Fonctionne hors ligne
- UtilisÃ© si l'API Ã©choue

### 3. **Mode Simulation** (Fallback) ğŸ­
- Transcriptions prÃ©-enregistrÃ©es pour dÃ©mo
- Aucune dÃ©pendance requise
- UtilisÃ© uniquement si les 2 autres modes Ã©chouent

---

## ğŸ“ Utilisation dans l'Application

### Avec Streamlit (Interface Web)

```bash
streamlit run app.py
```

1. Aller sur **"ğŸ“ Nouvelle DÃ©claration"**
2. Choisir un mode d'entrÃ©e :

#### **ğŸ¤ Enregistrement Audio** (RecommandÃ©)
- Cliquer sur le bouton microphone
- Parler en franÃ§ais ou arabe
- L'API Whisper transcrit automatiquement

#### **ğŸ“ Upload Audio**
- Uploader un fichier `.wav`, `.mp3`, `.m4a`, `.ogg`
- L'API traite le fichier
- Transcription affichÃ©e en quelques secondes

#### **ğŸ’¬ Simulation Textuelle**
- Mode texte pour tests rapides
- Pas de transcription audio

---

## ğŸ§ª Test avec Python

### Test Simple

```python
from modules.stt_module import STTEngine

# Initialiser avec API
engine = STTEngine(use_api=True)

# Transcrire un fichier
result = engine.transcribe_audio("mon_audio.wav", language="fr")

print(f"Transcription : {result.normalized_transcript}")
print(f"Langue dÃ©tectÃ©e : {result.language}")
print(f"Confiance : {result.confidence_score}")
```

### Test Complet

```bash
python test_whisper_api.py
```

---

## ğŸ¯ Formats Audio SupportÃ©s

L'API Whisper accepte :
- **WAV** (`.wav`)
- **MP3** (`.mp3`)
- **M4A** (`.m4a`)
- **OGG** (`.ogg`)
- **FLAC** (`.flac`)
- **WEBM** (`.webm`)

**Limite de taille** : 25 MB par fichier

---

## ğŸŒ Langues SupportÃ©es

L'API dÃ©tecte automatiquement la langue, mais vous pouvez forcer :

```python
# FranÃ§ais
result = engine.transcribe_audio("audio.wav", language="fr")

# Arabe
result = engine.transcribe_audio("audio.wav", language="ar")

# Anglais
result = engine.transcribe_audio("audio.wav", language="en")
```

Plus de 50 langues supportÃ©es au total !

---

## ğŸ”§ Configuration AvancÃ©e

### Changer la PrioritÃ© des Modes

```python
# Forcer le mode API uniquement
engine = STTEngine(use_api=True)

# Forcer le mode local uniquement
engine = STTEngine(use_api=False)
```

### Variables d'Environnement

Fichier `.env` :
```bash
# STT avec Whisper
WHISPER_API_KEY=7fk3Ppa7utGvvHJ7MGUYwV3K24FpxxJh

# Optionnel : Pour cognitive engine avancÃ©
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
```

---

## âš¡ Performance

### Mode API
- **Latence** : 2-5 secondes (selon taille fichier)
- **QualitÃ©** : Excellente (modÃ¨le Whisper-1)
- **CoÃ»t** : $0.006 par minute audio

### Mode Local
- **Latence** : Variable (selon modÃ¨le et hardware)
- **QualitÃ©** : Bonne Ã  excellente
- **CoÃ»t** : Gratuit (aprÃ¨s tÃ©lÃ©chargement du modÃ¨le)

### Mode Simulation
- **Latence** : InstantanÃ©
- **QualitÃ©** : PrÃ©dÃ©fini
- **CoÃ»t** : Gratuit

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : "ClÃ© API non trouvÃ©e"
```bash
# VÃ©rifier que .env existe
cat .env

# VÃ©rifier que python-dotenv est installÃ©
pip install python-dotenv
```

### ProblÃ¨me : "API Whisper error"
- VÃ©rifier la validitÃ© de la clÃ© API
- VÃ©rifier la connexion internet
- Le systÃ¨me basculera automatiquement en mode local ou simulation

### ProblÃ¨me : "Invalid audio file"
- VÃ©rifier le format du fichier (WAV, MP3, etc.)
- VÃ©rifier que le fichier n'est pas corrompu
- Taille maximale : 25 MB

---

## ğŸ“Š Exemple Complet

```python
from modules.stt_module import STTEngine
from modules.cognitive_engine import CognitiveClaimEngine
from modules.complexity_calculator import ComplexityCalculator

# 1. Transcrire l'audio
stt = STTEngine(use_api=True)
transcript = stt.transcribe_audio("client_appel.wav", language="fr")

print(f"ğŸ“ Transcription : {transcript.normalized_transcript}")
print(f"ğŸ­ Ã‰motions : {transcript.emotional_markers}")

# 2. Analyser le sinistre
cognitive = CognitiveClaimEngine()
claim = cognitive.analyze_claim(transcript)

print(f"ğŸ” Type : {claim.claim_type}")
print(f"ğŸ“… Date : {claim.incident_date}")

# 3. Calculer la complexitÃ©
calculator = ComplexityCalculator()
complexity = calculator.calculate(claim)

print(f"ğŸ“Š Score CCI : {complexity.total_cci}/100")
print(f"âš–ï¸ Niveau : {complexity.complexity_level}")
```

---

## ğŸ‰ Prochaines Ã‰tapes

1. **Tester** : `python test_whisper_api.py`
2. **Lancer l'app** : `streamlit run app.py`
3. **Enregistrer un sinistre** : Utiliser le microphone ou uploader un fichier
4. **Observer** : La transcription en temps rÃ©el avec l'API Whisper

---

## ğŸ“ Support

Pour toute question :
- Consulter [README.md](README.md)
- Consulter [LIVRAISON.md](LIVRAISON.md)
- ExÃ©cuter les tests : `python test_system.py`
