"""
Script de d√©monstration compl√®te du syst√®me √©motionnel
G√©n√®re des conversations simul√©es avec analyses √©motionnelles
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import numpy as np
import soundfile as sf
from datetime import datetime, timedelta
import random

from modules.emotion_integration import (
    process_audio_with_emotion_analysis,
    get_emotion_label_fr,
    get_emotion_color
)

# Sc√©narios de conversation r√©alistes
SCENARIOS = [
    {
        "client_id": "CLI001",
        "sinistre_id": "SIN001",
        "emotion": "anger",
        "transcription": "C'est INADMISSIBLE ! √áa fait 3 semaines que j'attends et PERSONNE ne me rappelle ! Mon dossier est URGENT !",
        "pitch_base": 250,  # Hz - voix tendue/aigu√´
        "energy": 0.08,     # Amplitude forte
        "tempo": 150        # BPM rapide
    },
    {
        "client_id": "CLI002",
        "sinistre_id": "SIN002",
        "emotion": "stress",
        "transcription": "Je suis vraiment stress√©, c'est tr√®s urgent, j'ai besoin d'une r√©ponse rapidement s'il vous pla√Æt.",
        "pitch_base": 210,
        "energy": 0.06,
        "tempo": 140
    },
    {
        "client_id": "CLI003",
        "sinistre_id": "SIN003",
        "emotion": "sadness",
        "transcription": "Je suis tellement triste... Personne ne peut m'aider avec mon dossier. Je me sens abandonn√©.",
        "pitch_base": 150,  # Voix basse
        "energy": 0.03,     # Faible
        "tempo": 90         # Lent
    },
    {
        "client_id": "CLI004",
        "sinistre_id": "SIN004",
        "emotion": "fear",
        "transcription": "J'ai vraiment peur que mon dossier soit refus√©... Je ne sais pas quoi faire si √ßa arrive.",
        "pitch_base": 200,
        "energy": 0.04,
        "tempo": 110
    },
    {
        "client_id": "CLI005",
        "sinistre_id": "SIN005",
        "emotion": "frustration",
        "transcription": "C'est la troisi√®me fois que j'appelle ! Toujours la m√™me r√©ponse ! Vous vous moquez de moi ?",
        "pitch_base": 230,
        "energy": 0.07,
        "tempo": 135
    },
    {
        "client_id": "CLI006",
        "sinistre_id": "SIN006",
        "emotion": "neutral",
        "transcription": "Bonjour, je souhaite d√©clarer un sinistre automobile survenu hier √† 14h30 sur la rocade.",
        "pitch_base": 180,
        "energy": 0.04,
        "tempo": 100
    },
    {
        "client_id": "CLI001",
        "sinistre_id": "SIN001",
        "emotion": "anger",
        "transcription": "Encore une fois ! Toujours les m√™mes excuses ! Je veux parler au responsable MAINTENANT !",
        "pitch_base": 270,
        "energy": 0.09,
        "tempo": 160
    },
    {
        "client_id": "CLI007",
        "sinistre_id": "SIN007",
        "emotion": "stress",
        "transcription": "S'il vous pla√Æt, c'est press√©, j'ai un rendez-vous dans une heure, il me faut cette attestation maintenant.",
        "pitch_base": 220,
        "energy": 0.065,
        "tempo": 145
    }
]


def generate_synthetic_audio(pitch_base, energy, tempo, duration=3.0, sample_rate=16000):
    """
    G√©n√®re un audio synth√©tique avec caract√©ristiques √©motionnelles
    
    Args:
        pitch_base: Fr√©quence de base (Hz)
        energy: Amplitude RMS
        tempo: Tempo (BPM, influence la modulation)
        duration: Dur√©e (secondes)
        sample_rate: Taux d'√©chantillonnage
        
    Returns:
        numpy array audio
    """
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # Onde de base (sinuso√Øde √† la fr√©quence pitch_base)
    audio = np.sin(2 * np.pi * pitch_base * t)
    
    # Ajouter harmoniques (plus r√©aliste)
    audio += 0.3 * np.sin(2 * np.pi * pitch_base * 2 * t)  # 2√®me harmonique
    audio += 0.15 * np.sin(2 * np.pi * pitch_base * 3 * t)  # 3√®me harmonique
    
    # Modulation tempo (vibrato √©motionnel)
    modulation_freq = tempo / 60  # Hz
    modulation = 1 + 0.1 * np.sin(2 * np.pi * modulation_freq * t)
    audio = audio * modulation
    
    # Ajuster l'√©nergie (amplitude)
    audio = audio * energy
    
    # Ajouter bruit (respiration, fond)
    noise = np.random.normal(0, energy * 0.1, len(audio))
    audio = audio + noise
    
    # Normaliser
    audio = audio / np.max(np.abs(audio)) * 0.8
    
    return audio.astype(np.float32)


def run_demo():
    """Ex√©cute la d√©monstration compl√®te"""
    print("\n" + "=" * 70)
    print("üé≠ D√âMONSTRATION SYST√àME D'ANALYSE √âMOTIONNELLE")
    print("=" * 70)
    
    print("\nüìä Sc√©narios √† simuler:")
    for i, scenario in enumerate(SCENARIOS, 1):
        emotion_fr = get_emotion_label_fr(scenario['emotion'])
        color = get_emotion_color(scenario['emotion'])
        print(f"{i}. [{scenario['sinistre_id']}] {emotion_fr} - {scenario['transcription'][:50]}...")
    
    print("\nüé¨ G√©n√©ration des audios et analyses en cours...\n")
    
    results = []
    temp_audio_dir = Path("data/temp_audio")
    temp_audio_dir.mkdir(parents=True, exist_ok=True)
    
    for i, scenario in enumerate(SCENARIOS, 1):
        print(f"\n{'‚îÄ' * 70}")
        print(f"[{i}/{len(SCENARIOS)}] {scenario['sinistre_id']} - {get_emotion_label_fr(scenario['emotion'])}")
        print(f"{'‚îÄ' * 70}")
        
        # G√©n√©rer audio synth√©tique
        print("üéôÔ∏è G√©n√©ration audio synth√©tique...")
        audio = generate_synthetic_audio(
            pitch_base=scenario['pitch_base'],
            energy=scenario['energy'],
            tempo=scenario['tempo'],
            duration=3.0
        )
        
        # Sauvegarder l'audio
        timestamp = datetime.now() - timedelta(minutes=len(SCENARIOS) - i)  # √âchelonner dans le temps
        audio_filename = f"demo_{scenario['sinistre_id']}_{timestamp.strftime('%Y%m%d_%H%M%S')}.wav"
        audio_path = temp_audio_dir / audio_filename
        
        sf.write(audio_path, audio, 16000)
        print(f"‚úÖ Audio sauvegard√©: {audio_filename}")
        
        # Analyser avec le syst√®me complet
        print("üé≠ Analyse √©motionnelle en cours...")
        emotion_data = process_audio_with_emotion_analysis(
            str(audio_path),
            scenario['transcription'],
            client_id=scenario['client_id'],
            sinistre_id=scenario['sinistre_id'],
            save_audio=True
        )
        
        # Afficher r√©sultats
        detected_emotion = emotion_data['dominant_emotion']['label']
        confidence = emotion_data['dominant_emotion']['confidence']
        alert_level = emotion_data['alert_level']
        
        emotion_fr = get_emotion_label_fr(detected_emotion)
        expected_fr = get_emotion_label_fr(scenario['emotion'])
        
        # Symboles d'alerte
        alert_symbols = {
            'critical': 'üö®',
            'high': '‚ö†Ô∏è',
            'medium': 'üíô',
            'low': 'üîµ',
            'none': 'üü¢'
        }
        
        print(f"\nüìä R√âSULTATS:")
        print(f"  Attendue:  {expected_fr}")
        print(f"  D√©tect√©e:  {emotion_fr} ({confidence:.1f}%)")
        print(f"  Alerte:    {alert_symbols.get(alert_level, '‚ùì')} {alert_level.upper()}")
        print(f"  Match:     {'‚úÖ EXACT' if detected_emotion == scenario['emotion'] else '‚ö†Ô∏è DIFF√âRENT'}")
        
        results.append({
            'sinistre_id': scenario['sinistre_id'],
            'expected': scenario['emotion'],
            'detected': detected_emotion,
            'confidence': confidence,
            'alert_level': alert_level,
            'match': detected_emotion == scenario['emotion']
        })
    
    # R√©sum√© final
    print("\n" + "=" * 70)
    print("üìà R√âSUM√â DE LA D√âMONSTRATION")
    print("=" * 70)
    
    total = len(results)
    matches = sum(1 for r in results if r['match'])
    accuracy = (matches / total) * 100
    
    print(f"\nPr√©cision globale: {matches}/{total} ({accuracy:.1f}%)")
    
    # Statistiques par √©motion
    print("\nüìä D√©tails par √©motion:")
    for emotion in ['anger', 'stress', 'sadness', 'fear', 'frustration', 'neutral']:
        emotion_results = [r for r in results if r['expected'] == emotion]
        if emotion_results:
            emotion_matches = sum(1 for r in emotion_results if r['match'])
            emotion_total = len(emotion_results)
            emotion_accuracy = (emotion_matches / emotion_total) * 100
            emotion_fr = get_emotion_label_fr(emotion)
            
            avg_confidence = np.mean([r['confidence'] for r in emotion_results])
            
            print(f"  {emotion_fr:12} : {emotion_matches}/{emotion_total} ({emotion_accuracy:.0f}%) - Confiance moy: {avg_confidence:.1f}%")
    
    # Alertes g√©n√©r√©es
    print("\nüö® Alertes g√©n√©r√©es:")
    critical_alerts = [r for r in results if r['alert_level'] == 'critical']
    high_alerts = [r for r in results if r['alert_level'] == 'high']
    
    print(f"  Critiques: {len(critical_alerts)}")
    for alert in critical_alerts:
        print(f"    - {alert['sinistre_id']}: {get_emotion_label_fr(alert['detected'])} ({alert['confidence']:.1f}%)")
    
    print(f"  Hautes:    {len(high_alerts)}")
    for alert in high_alerts:
        print(f"    - {alert['sinistre_id']}: {get_emotion_label_fr(alert['detected'])} ({alert['confidence']:.1f}%)")
    
    # Fichiers g√©n√©r√©s
    print("\nüìÅ Fichiers g√©n√©r√©s:")
    audio_files = list(temp_audio_dir.glob("demo_*.wav"))
    emotion_files = list(temp_audio_dir.glob("demo_*.emotion.json"))
    
    print(f"  Audios:    {len(audio_files)} fichiers WAV")
    print(f"  Analyses:  {len(emotion_files)} fichiers JSON")
    
    # Prochaines √©tapes
    print("\n" + "=" * 70)
    print("‚úÖ D√âMONSTRATION TERMIN√âE")
    print("=" * 70)
    
    print("\nüöÄ V√©rifier les r√©sultats:")
    print("  1. Dashboard web: http://localhost:3001/")
    print("  2. Page √©motions: http://localhost:3001/emotions")
    print("  3. API backend:   http://localhost:8000/api/v1/emotions/dashboard-summary")
    print("  4. Fichiers JSON: data/temp_audio/*.emotion.json")
    
    print("\nüí° Les donn√©es sont maintenant visibles dans:")
    print("  - Le dashboard principal (section √©motions)")
    print("  - La page d√©taill√©e des √©motions")
    print("  - Les analyses Streamlit (si upload)")


if __name__ == "__main__":
    try:
        run_demo()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è D√©monstration interrompue par l'utilisateur")
    except Exception as e:
        print(f"\n\n‚ùå ERREUR: {e}")
        import traceback
        traceback.print_exc()
