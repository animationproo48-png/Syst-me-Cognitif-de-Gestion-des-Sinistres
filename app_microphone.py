"""
Application Microphone Haute Qualit√© - Mode Dialogue LAMA
Enregistrement direct en WAV sans compression (comme les fichiers upload√©s)
"""

import streamlit as st
import os
import wave
import pyaudio
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# Imports m√©tier
from modules.stt_module import STTEngine
from modules.tts_module import TTSEngine
from modules.cognitive_engine import CognitiveClaimEngine
from modules.conversation_manager import ConversationManager, ConversationPhase
from models.claim_models import ClaimDigitalTwin, ClaimState

# Configuration Streamlit
st.set_page_config(
    page_title="Service Gestion Sinistre - Microphone",
    page_icon="üéôÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialisation session state
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False
    st.session_state.conversation_active = False
    st.session_state.digital_twin = None
    st.session_state.conversation_manager = None
    st.session_state.conversation_history = []
    st.session_state.current_phase = None
    st.session_state.recording = False


def initialize_session():
    """Initialise une nouvelle session de conversation"""
    claim_id = f"CLM-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
    
    # Cr√©er le Digital Twin
    digital_twin = ClaimDigitalTwin(
        claim_id=claim_id,
        current_state=ClaimState.RECEIVED,
        timestamp=datetime.now()
    )
    
    # Initialiser le gestionnaire de conversation
    conversation_manager = ConversationManager(digital_twin)
    
    st.session_state.digital_twin = digital_twin
    st.session_state.conversation_manager = conversation_manager
    st.session_state.conversation_active = True
    st.session_state.session_initialized = True
    st.session_state.claim_id = claim_id
    st.session_state.conversation_history = []
    
    return digital_twin, conversation_manager, claim_id


def play_audio(audio_path):
    """Joue un fichier audio"""
    if audio_path and os.path.exists(audio_path):
        with open(audio_path, 'rb') as audio_file:
            st.audio(audio_file, format='audio/wav')


def log_conversation(speaker: str, text: str, audio_path: str = None):
    """Enregistre un tour de conversation"""
    st.session_state.conversation_history.append({
        "timestamp": datetime.now(),
        "speaker": speaker,
        "text": text,
        "audio": audio_path
    })


def record_audio_wav(duration: int = 10, sample_rate: int = 16000):
    """
    Enregistre l'audio directement en WAV haute qualit√© (16kHz, 16-bit, mono).
    Sans compression WebM comme st.audio_input().
    
    Args:
        duration: Dur√©e maximale en secondes
        sample_rate: Fr√©quence d'√©chantillonnage (16000 Hz optimal pour STT)
    
    Returns:
        Chemin du fichier WAV enregistr√©
    """
    try:
        # Configuration PyAudio
        CHUNK = 1024
        FORMAT = 8  # 16-bit (pyaudio.paInt16)
        CHANNELS = 1  # Mono
        
        audio = pyaudio.PyAudio()
        
        stream = audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=sample_rate,
            input=True,
            frames_per_buffer=CHUNK
        )
        
        # Fichier de sortie
        output_path = Path("data/temp") / f"mic_record_{datetime.now().strftime('%H%M%S')}.wav"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Enregistrement
        st.info(f"üé§ Enregistrement en cours ({duration}s)...")
        frames = []
        
        for _ in range(0, int(sample_rate / CHUNK * duration)):
            try:
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames.append(data)
            except:
                break
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        
        # Sauvegarde WAV
        with wave.open(str(output_path), 'wb') as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(audio.get_sample_size(FORMAT))
            wf.setframerate(sample_rate)
            wf.writeframes(b''.join(frames))
        
        st.success(f"‚úÖ Enregistrement sauvegard√©: {output_path.stat().st_size} bytes")
        return str(output_path)
        
    except Exception as e:
        st.error(f"‚ùå Erreur microphone: {e}")
        st.info("üí° Conseil: Utilisez app_upload.py pour uploader des fichiers pr√©-enregistr√©s")
        return None


# ===== INTERFACE PRINCIPALE =====

st.title("üéôÔ∏è Service Gestion Sinistre - Microphone Haute Qualit√©")
st.markdown("""
Syst√®me conversationnel LAMA interactif - Enregistrement direct
- **Enregistrez** directement via microphone (WAV haute qualit√©)
- **Transcription** automatique en fran√ßais
- **Analyse** cognitive du sinistre
- **Dialogue** LAMA avec r√©ponses vocales

**üí° Conseil**: Pour meilleure qualit√©, pr√©f√©rez [app_upload.py](http://localhost:8501?app=app_upload.py) (upload de fichiers)
""")

# ===== SECTION 1: INITIALISATION =====
col1, col2 = st.columns(2)

with col1:
    if st.button("üéôÔ∏è Lancer une conversation", key="start_conversation", use_container_width=True):
        digital_twin, conv_manager, claim_id = initialize_session()
        
        with st.status("üéôÔ∏è Session initialis√©e...", expanded=True) as status:
            st.write(f"‚úÖ Claim ID: `{claim_id}`")
            st.write(f"‚úÖ √âtat: {digital_twin.current_state.value}")
            
            # √âtape 1: Accueil TTS
            st.write("\nüì¢ **Accueil vocal...**")
            tts_engine = TTSEngine(language="fr")
            greeting_text = conv_manager.get_greeting_prompt()
            
            greeting_audio = Path("data/audio_responses") / f"greeting_{claim_id}.mp3"
            greeting_audio.parent.mkdir(parents=True, exist_ok=True)
            tts_engine.synthesize(greeting_text, str(greeting_audio), tone="professional")
            
            st.write(f"üéôÔ∏è **Syst√®me**: {greeting_text}")
            play_audio(str(greeting_audio))
            
            log_conversation("System", greeting_text, str(greeting_audio))
            
            # Passer √† la phase LISTEN apr√®s le greeting
            conv_manager.current_phase = ConversationPhase.LISTEN
            
            status.update(label="‚úÖ Accueil termin√© - En attente de votre enregistrement", state="complete")

with col2:
    if st.button("‚ùå Fermer conversation", key="end_conversation", use_container_width=True):
        st.session_state.conversation_active = False
        st.session_state.session_initialized = False
        st.info("Conversation ferm√©e. Cliquez sur 'Lancer' pour recommencer.")


# ===== SECTION 2: ENREGISTREMENT MICROPHONE =====
if st.session_state.session_initialized and st.session_state.conversation_active:
    st.divider()
    st.subheader("üé§ Enregistrement Microphone")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        duration = st.slider("Dur√©e maximale (secondes)", 5, 60, 15)
    
    with col2:
        if st.button("üî¥ D√©marrer enregistrement", key="record_btn", use_container_width=True):
            st.session_state.recording = True
    
    with col3:
        if st.button("‚èπÔ∏è Arr√™ter enregistrement", key="stop_btn", use_container_width=True):
            st.session_state.recording = False
    
    if st.session_state.recording:
        audio_file = record_audio_wav(duration=duration)
        st.session_state.recording = False
        
        if audio_file:
            # √âtape 2: STT
            with st.status("üîÑ Traitement...", expanded=True) as status:
                st.write("üìù Transcription en cours...")
                
                stt_engine = STTEngine()
                metadata = stt_engine.transcribe_audio(audio_file)
                
                st.write(f"‚úÖ Langue d√©tect√©e: **{metadata.language}**")
                st.write(f"üìù Transcription originale: **{metadata.original_transcript[:100]}...**")
                st.write(f"üìù Transcription traduite: **{metadata.normalized_transcript[:100]}...**")
                
                user_text = metadata.normalized_transcript
                log_conversation("Client", user_text, audio_file)
                
                # √âtape 3: Analyse cognitive
                st.write("\nüß† Analyse cognitive en cours...")
                
                conv_manager = st.session_state.conversation_manager
                
                cognitive_engine = CognitiveClaimEngine()
                cognitive_analysis = cognitive_engine.analyze_claim(metadata)
                
                st.write(f"‚úÖ Type de sinistre: {cognitive_analysis.claim_type.value}")
                st.write(f"‚úÖ Stress √©motionnel: {cognitive_analysis.emotional_stress_level}/10")
                st.write(f"‚úÖ Phase actuelle: {conv_manager.current_phase.value}")
                
                # √âtape 4: Gestion conversation LAMA
                st.write("\nüí¨ R√©ponse du syst√®me (m√©thode LAMA)...")
                
                # Selon la phase actuelle
                if conv_manager.current_phase == ConversationPhase.GREETING:
                    # Si encore en phase GREETING, passer √† LISTEN
                    conv_manager.current_phase = ConversationPhase.LISTEN
                
                if conv_manager.current_phase == ConversationPhase.LISTEN:
                    ack_text, summary_text, next_q = conv_manager.process_accident_description(
                        user_text,
                        {
                            "claim_type": cognitive_analysis.claim_type.value,
                            "location": " / ".join(cognitive_analysis.location or []),
                            "damages": cognitive_analysis.damages_description,
                            "emotional_stress": cognitive_analysis.emotional_stress_level
                        }
                    )
                    
                    # G√©n√©rer les r√©ponses TTS
                    tts_engine = TTSEngine(language="fr")
                    
                    # ACKNOWLEDGE
                    st.write(f"\n1Ô∏è‚É£ **Empathie**: {ack_text}")
                    ack_audio = Path("data/audio_responses") / f"ack_{datetime.now().strftime('%H%M%S')}.mp3"
                    tts_engine.synthesize(ack_text, str(ack_audio), tone="empathetic")
                    st.audio(open(ack_audio, 'rb'), format='audio/mp3')
                    log_conversation("System", ack_text, str(ack_audio))
                    
                    # MAKE STATEMENT
                    st.write(f"\n2Ô∏è‚É£ **R√©sum√©**: {summary_text}")
                    summary_audio = Path("data/audio_responses") / f"summary_{datetime.now().strftime('%H%M%S')}.mp3"
                    tts_engine.synthesize(summary_text, str(summary_audio), tone="professional")
                    st.audio(open(summary_audio, 'rb'), format='audio/mp3')
                    log_conversation("System", summary_text, str(summary_audio))
                    
                    # ASK QUESTIONS
                    st.write(f"\n3Ô∏è‚É£ **Question**: {next_q}")
                    question_audio = Path("data/audio_responses") / f"q_{datetime.now().strftime('%H%M%S')}.mp3"
                    tts_engine.synthesize(next_q, str(question_audio), tone="professional")
                    st.audio(open(question_audio, 'rb'), format='audio/mp3')
                    log_conversation("System", next_q, str(question_audio))
                
                status.update(label="‚úÖ Tour termin√©", state="complete")
                
                # Afficher le statut actuel
                st.divider()
                st.subheader("üìä Statut de collecte")
                phase_status = conv_manager.get_phase_status()
                
                cols = st.columns(4)
                cols[0].metric("Identifi√©", "‚úÖ" if phase_status["caller_id_collected"] else "‚è≥")
                cols[1].metric("V√©hicule", "‚úÖ" if phase_status["vehicle_collected"] else "‚è≥")
                cols[2].metric("Nom", "‚úÖ" if phase_status["name_collected"] else "‚è≥")
                cols[3].metric("CIN", "‚úÖ" if phase_status["cin_collected"] else "‚è≥")
                
                if phase_status["all_required_info"]:
                    st.success("üéâ Tous les champs requis collect√©s!")


# ===== SECTION 3: HISTORIQUE =====
if st.session_state.conversation_history:
    st.divider()
    st.subheader("üìã Historique de conversation")
    
    for item in st.session_state.conversation_history:
        with st.expander(f"{item['timestamp'].strftime('%H:%M:%S')} - {item['speaker']}"):
            st.write(f"**{item['speaker']}**: {item['text']}")
            if item['audio']:
                try:
                    st.audio(item['audio'])
                except:
                    st.write(f"Audio: {item['audio']}")

load_dotenv()
